{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":10676808,"sourceType":"datasetVersion","datasetId":6613608},{"sourceId":251405,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":214909,"modelId":236600}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:29:08.706622Z","iopub.execute_input":"2025-02-07T05:29:08.706934Z","iopub.status.idle":"2025-02-07T05:29:09.045632Z","shell.execute_reply.started":"2025-02-07T05:29:08.706911Z","shell.execute_reply":"2025-02-07T05:29:09.044732Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/arogoai-llm/LLM_test.csv\n/kaggle/input/arogoai-llm/LLM_data.csv\n/kaggle/input/arogo_epoch1_checkpoints/transformers/default/1/config.json\n/kaggle/input/arogo_epoch1_checkpoints/transformers/default/1/trainer_state.json\n/kaggle/input/arogo_epoch1_checkpoints/transformers/default/1/training_args.bin\n/kaggle/input/arogo_epoch1_checkpoints/transformers/default/1/scheduler.pt\n/kaggle/input/arogo_epoch1_checkpoints/transformers/default/1/model.safetensors\n/kaggle/input/arogo_epoch1_checkpoints/transformers/default/1/optimizer.pt\n/kaggle/input/arogo_epoch1_checkpoints/transformers/default/1/rng_state.pth\n/kaggle/input/arogo_epoch1_checkpoints/transformers/default/1/generation_config.json\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"!pip install evaluate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:29:09.046656Z","iopub.execute_input":"2025-02-07T05:29:09.047039Z","iopub.status.idle":"2025-02-07T05:29:13.437975Z","shell.execute_reply.started":"2025-02-07T05:29:09.047018Z","shell.execute_reply":"2025-02-07T05:29:13.436992Z"}},"outputs":[{"name":"stdout","text":"Collecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.67.1)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.27.0)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.10)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy>=1.17->evaluate) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\nRequirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy>=1.17->evaluate) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy>=1.17->evaluate) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy>=1.17->evaluate) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy>=1.17->evaluate) (2024.2.0)\nDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.3\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install rouge_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:29:13.439917Z","iopub.execute_input":"2025-02-07T05:29:13.440169Z","iopub.status.idle":"2025-02-07T05:29:18.674320Z","shell.execute_reply.started":"2025-02-07T05:29:13.440147Z","shell.execute_reply":"2025-02-07T05:29:18.673481Z"}},"outputs":[{"name":"stdout","text":"Collecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.17.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2025.0.1)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2022.0.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.10/dist-packages (from numpy->rouge_score) (2.4.1)\nRequirement already satisfied: intel-openmp>=2024 in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.10/dist-packages (from mkl->numpy->rouge_score) (2022.0.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.10/dist-packages (from tbb==2022.*->mkl->numpy->rouge_score) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.10/dist-packages (from mkl_umath->numpy->rouge_score) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.10/dist-packages (from intel-openmp>=2024->mkl->numpy->rouge_score) (2024.2.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=9a7145f85ff5243fc33026856707de90c9cfabfab70ac85bee0e028fb8d01c20\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer\nimport torch\nfrom torch.utils.data import Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:29:18.675966Z","iopub.execute_input":"2025-02-07T05:29:18.676283Z","iopub.status.idle":"2025-02-07T05:29:40.219835Z","shell.execute_reply.started":"2025-02-07T05:29:18.676252Z","shell.execute_reply":"2025-02-07T05:29:40.219161Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"from transformers import (\n    AutoTokenizer,\n    AutoModelForSeq2SeqLM,\n    Seq2SeqTrainingArguments,\n    Seq2SeqTrainer,\n)\nfrom torch.utils.data import Dataset\nfrom sklearn.model_selection import train_test_split\nimport logging\n\n# Set up logging\nlogging.basicConfig(\n    filename=\"training_log.log\",\n    level=logging.INFO,\n    format=\"%(asctime)s - %(message)s\",\n    datefmt=\"%Y-%m-%d %H:%M:%S\",\n)\nlogger = logging.getLogger()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:29:40.220685Z","iopub.execute_input":"2025-02-07T05:29:40.221172Z","iopub.status.idle":"2025-02-07T05:29:40.242261Z","shell.execute_reply.started":"2025-02-07T05:29:40.221149Z","shell.execute_reply":"2025-02-07T05:29:40.241511Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"os.environ[\"WANDB_DISABLED\"] = \"true\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:29:40.243194Z","iopub.execute_input":"2025-02-07T05:29:40.243499Z","iopub.status.idle":"2025-02-07T05:29:40.355196Z","shell.execute_reply.started":"2025-02-07T05:29:40.243469Z","shell.execute_reply":"2025-02-07T05:29:40.354514Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class EntityValueDataset(Dataset):\n    def __init__(self, encodings, labels):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        item[\"labels\"] = torch.tensor(self.labels[\"input_ids\"][idx])\n        return item\n\n    def __len__(self):\n        return len(self.labels[\"input_ids\"])\n\nclass EntityValueDatasetTest(Dataset):\n    def __init__(self, encodings):\n        self.encodings = encodings\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        return item\n\n    def __len__(self):\n        return len(next(iter(self.encodings.values())))\n\ndef prepare_data(df):\n    inputs = []\n    targets = []\n    for _, row in df.iterrows():\n        input_text = f\"Behave like an experienced psychiatrist and answer: {row['Context']}\"\n        inputs.append(f\"Behave like an experienced psychiatrist and answer: {row['Context']}\")\n        targets.append(str(row[\"Response\"]))\n    return inputs, targets","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:29:40.356046Z","iopub.execute_input":"2025-02-07T05:29:40.356286Z","iopub.status.idle":"2025-02-07T05:29:40.368617Z","shell.execute_reply.started":"2025-02-07T05:29:40.356267Z","shell.execute_reply":"2025-02-07T05:29:40.367709Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def batch_predict(model, tokenizer, dataset, batch_size=16):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model.eval()\n\n    predictions = []\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=False)\n    with torch.no_grad():\n        for batch in dataloader:\n            inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n            outputs = model.generate(**inputs, max_length=75, do_sample=False)\n            predictions.extend([tokenizer.decode(output, skip_special_tokens=True) for output in outputs])\n    return predictions\n\n\ntrain_df = pd.read_csv(\"/kaggle/input/arogoai-llm/LLM_data.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/arogoai-llm/LLM_test.csv\")[0:30000]\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:29:40.370891Z","iopub.execute_input":"2025-02-07T05:29:40.371133Z","iopub.status.idle":"2025-02-07T05:29:44.688355Z","shell.execute_reply.started":"2025-02-07T05:29:40.371111Z","shell.execute_reply":"2025-02-07T05:29:44.687694Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"train_df.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:29:44.689760Z","iopub.execute_input":"2025-02-07T05:29:44.689976Z","iopub.status.idle":"2025-02-07T05:29:44.708548Z","shell.execute_reply.started":"2025-02-07T05:29:44.689957Z","shell.execute_reply":"2025-02-07T05:29:44.707648Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"   Unnamed: 0                                            Context  \\\n0      802866  It makes me doubt myself, Alex. I start questi...   \n1      693266  I've been feeling a mix of emotions, Alex. I'v...   \n2      670022  Well, I've been neglecting certain aspects of ...   \n\n                                            Response  \n0  I can understand why you feel that way, Charli...  \n1  It's completely understandable to have such a ...  \n2  It takes courage to acknowledge that, Charlie....  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Context</th>\n      <th>Response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>802866</td>\n      <td>It makes me doubt myself, Alex. I start questi...</td>\n      <td>I can understand why you feel that way, Charli...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>693266</td>\n      <td>I've been feeling a mix of emotions, Alex. I'v...</td>\n      <td>It's completely understandable to have such a ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>670022</td>\n      <td>Well, I've been neglecting certain aspects of ...</td>\n      <td>It takes courage to acknowledge that, Charlie....</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"train_df = train_df.drop(columns = ['Unnamed: 0'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:29:44.709248Z","iopub.execute_input":"2025-02-07T05:29:44.709573Z","iopub.status.idle":"2025-02-07T05:29:44.767584Z","shell.execute_reply.started":"2025-02-07T05:29:44.709541Z","shell.execute_reply":"2025-02-07T05:29:44.766746Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"train_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:29:44.768309Z","iopub.execute_input":"2025-02-07T05:29:44.768520Z","iopub.status.idle":"2025-02-07T05:29:44.848940Z","shell.execute_reply.started":"2025-02-07T05:29:44.768502Z","shell.execute_reply":"2025-02-07T05:29:44.848280Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 300000 entries, 0 to 299999\nData columns (total 2 columns):\n #   Column    Non-Null Count   Dtype \n---  ------    --------------   ----- \n 0   Context   299945 non-null  object\n 1   Response  299983 non-null  object\ndtypes: object(2)\nmemory usage: 4.6+ MB\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"train_df.dropna(inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:29:44.849751Z","iopub.execute_input":"2025-02-07T05:29:44.850005Z","iopub.status.idle":"2025-02-07T05:29:44.943595Z","shell.execute_reply.started":"2025-02-07T05:29:44.849985Z","shell.execute_reply":"2025-02-07T05:29:44.942712Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_df.duplicated().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:29:44.944349Z","iopub.execute_input":"2025-02-07T05:29:44.944589Z","iopub.status.idle":"2025-02-07T05:29:45.414583Z","shell.execute_reply.started":"2025-02-07T05:29:44.944570Z","shell.execute_reply":"2025-02-07T05:29:45.413866Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"4271"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"train_df.drop_duplicates(inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:29:45.415289Z","iopub.execute_input":"2025-02-07T05:29:45.415552Z","iopub.status.idle":"2025-02-07T05:29:45.895362Z","shell.execute_reply.started":"2025-02-07T05:29:45.415531Z","shell.execute_reply":"2025-02-07T05:29:45.894474Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"test_df.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:29:45.896272Z","iopub.execute_input":"2025-02-07T05:29:45.896599Z","iopub.status.idle":"2025-02-07T05:29:45.911155Z","shell.execute_reply.started":"2025-02-07T05:29:45.896570Z","shell.execute_reply":"2025-02-07T05:29:45.910256Z"}},"outputs":[{"name":"stdout","text":"<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 30000 entries, 0 to 29999\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype \n---  ------      --------------  ----- \n 0   Unnamed: 0  30000 non-null  int64 \n 1   Context     29991 non-null  object\n 2   Response    29999 non-null  object\ndtypes: int64(1), object(2)\nmemory usage: 703.2+ KB\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"test_df = test_df.drop(columns = ['Unnamed: 0'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:29:45.912050Z","iopub.execute_input":"2025-02-07T05:29:45.912324Z","iopub.status.idle":"2025-02-07T05:29:45.928775Z","shell.execute_reply.started":"2025-02-07T05:29:45.912304Z","shell.execute_reply":"2025-02-07T05:29:45.927984Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"test_df.dropna(inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:29:45.929713Z","iopub.execute_input":"2025-02-07T05:29:45.929994Z","iopub.status.idle":"2025-02-07T05:29:45.947298Z","shell.execute_reply.started":"2025-02-07T05:29:45.929966Z","shell.execute_reply":"2025-02-07T05:29:45.946536Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"test_df.duplicated().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:29:45.948167Z","iopub.execute_input":"2025-02-07T05:29:45.948475Z","iopub.status.idle":"2025-02-07T05:29:45.996296Z","shell.execute_reply.started":"2025-02-07T05:29:45.948427Z","shell.execute_reply":"2025-02-07T05:29:45.995545Z"}},"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"0"},"metadata":{}}],"execution_count":18},{"cell_type":"code","source":"train_inputs, train_targets = prepare_data(train_df)\ntest_inputs, test_targets = prepare_data(test_df)\n\ntrain_inputs, eval_inputs, train_targets, eval_targets = train_test_split(train_inputs, train_targets, test_size=0.1, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:29:45.997048Z","iopub.execute_input":"2025-02-07T05:29:45.997273Z","iopub.status.idle":"2025-02-07T05:30:00.568363Z","shell.execute_reply.started":"2025-02-07T05:29:45.997255Z","shell.execute_reply":"2025-02-07T05:30:00.567687Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"train_inputs[8]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:30:00.569146Z","iopub.execute_input":"2025-02-07T05:30:00.569366Z","iopub.status.idle":"2025-02-07T05:30:00.574344Z","shell.execute_reply.started":"2025-02-07T05:30:00.569348Z","shell.execute_reply":"2025-02-07T05:30:00.573482Z"}},"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"'Behave like an experienced psychiatrist and answer: I think this is a good starting point for now. I appreciate your guidance and support, Alex. I feel a bit more motivated to have that conversation with my partner and focus on building a fulfilling life for myself. Thank you.'"},"metadata":{}}],"execution_count":20},{"cell_type":"code","source":"train_targets[8]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:30:00.575135Z","iopub.execute_input":"2025-02-07T05:30:00.575390Z","iopub.status.idle":"2025-02-07T05:30:00.590826Z","shell.execute_reply.started":"2025-02-07T05:30:00.575360Z","shell.execute_reply":"2025-02-07T05:30:00.590029Z"}},"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"\"You're very welcome, Charlie. It's been a pleasure supporting you. Remember, you have the power to create positive changes in your personal relationships and your life as a whole. Feel free to reach out whenever you feel the need for further guidance or simply to share your progress. Sending you strength and motivation in your journey ahead.\""},"metadata":{}}],"execution_count":21},{"cell_type":"code","source":"model_name = \"google-t5/t5-base\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\n# Tokenize data\ntrain_encodings = tokenizer(train_inputs, truncation=True, padding=True, max_length=300)\ntrain_target_encodings = tokenizer(train_targets, truncation=True, padding=True, max_length=75)\n\neval_encodings = tokenizer(eval_inputs, truncation=True, padding=True, max_length=300)\neval_target_encodings = tokenizer(eval_targets, truncation=True, padding=True, max_length=75)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:30:00.591604Z","iopub.execute_input":"2025-02-07T05:30:00.591872Z","iopub.status.idle":"2025-02-07T05:31:12.470695Z","shell.execute_reply.started":"2025-02-07T05:30:00.591843Z","shell.execute_reply":"2025-02-07T05:31:12.469995Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee3e692b95eb44da95dd10acf2d56ac6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"78bd8a9dfb0a4990abdd66ff1be2c17b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8954efcff18645b5a55625d3d734b1bb"}},"metadata":{}}],"execution_count":22},{"cell_type":"code","source":"train_encodings[10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:31:12.473249Z","iopub.execute_input":"2025-02-07T05:31:12.473511Z","iopub.status.idle":"2025-02-07T05:31:12.478230Z","shell.execute_reply.started":"2025-02-07T05:31:12.473490Z","shell.execute_reply":"2025-02-07T05:31:12.477474Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"Encoding(num_tokens=300, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"test_encodings = tokenizer(test_inputs, truncation=True, padding=True, max_length=300)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:31:12.479136Z","iopub.execute_input":"2025-02-07T05:31:12.479405Z","iopub.status.idle":"2025-02-07T05:31:15.780718Z","shell.execute_reply.started":"2025-02-07T05:31:12.479386Z","shell.execute_reply":"2025-02-07T05:31:15.779987Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"train_dataset = EntityValueDataset(train_encodings, train_target_encodings)\neval_dataset = EntityValueDataset(eval_encodings, eval_target_encodings)\ntest_dataset = EntityValueDatasetTest(test_encodings)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:31:15.781515Z","iopub.execute_input":"2025-02-07T05:31:15.781813Z","iopub.status.idle":"2025-02-07T05:31:15.785827Z","shell.execute_reply.started":"2025-02-07T05:31:15.781782Z","shell.execute_reply":"2025-02-07T05:31:15.784872Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"train_dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:31:15.786594Z","iopub.execute_input":"2025-02-07T05:31:15.786802Z","iopub.status.idle":"2025-02-07T05:31:15.800922Z","shell.execute_reply.started":"2025-02-07T05:31:15.786785Z","shell.execute_reply":"2025-02-07T05:31:15.800168Z"}},"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"<__main__.EntityValueDataset at 0x79dd3804c550>"},"metadata":{}}],"execution_count":26},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T21:15:13.968703Z","iopub.execute_input":"2025-02-06T21:15:13.969028Z","iopub.status.idle":"2025-02-06T21:15:19.504278Z","shell.execute_reply.started":"2025-02-06T21:15:13.969000Z","shell.execute_reply":"2025-02-06T21:15:19.503471Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/892M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb26f9d06cf049daa430c21b7f49663c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"07ae2a9032434955b7bdb8fd621698ff"}},"metadata":{}},{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n)"},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"training_args = Seq2SeqTrainingArguments(\n    output_dir=\"./results\",\n    num_train_epochs=1,\n    per_device_train_batch_size=24,\n    per_device_eval_batch_size=24,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=2,\n    load_best_model_at_end=True,\n    learning_rate=1e-3,\n\n)\n\n# Trainer\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n)\n\ntrainer.train()\n\nmodel.save_pretrained(\"./fine_tuned_t5\")\ntokenizer.save_pretrained(\"./fine_tuned_t5\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T21:15:29.667573Z","iopub.execute_input":"2025-02-06T21:15:29.667875Z","iopub.status.idle":"2025-02-06T21:16:33.250644Z","shell.execute_reply.started":"2025-02-06T21:15:29.667852Z","shell.execute_reply":"2025-02-06T21:16:33.249702Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='75' max='75' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [75/75 00:59, Epoch 1/1]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>1.639800</td>\n      <td>1.431756</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"},{"execution_count":28,"output_type":"execute_result","data":{"text/plain":"('./fine_tuned_t5/tokenizer_config.json',\n './fine_tuned_t5/special_tokens_map.json',\n './fine_tuned_t5/spiece.model',\n './fine_tuned_t5/added_tokens.json',\n './fine_tuned_t5/tokenizer.json')"},"metadata":{}}],"execution_count":28},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(\"./fine_tuned_t5\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:11:01.165490Z","iopub.execute_input":"2025-02-05T22:11:01.165742Z","iopub.status.idle":"2025-02-05T22:11:01.755172Z","shell.execute_reply.started":"2025-02-05T22:11:01.165721Z","shell.execute_reply":"2025-02-05T22:11:01.754457Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n)"},"metadata":{}}],"execution_count":30},{"cell_type":"code","source":"import evaluate\n\nrouge_metric = evaluate.load(\"rouge\")\n\ndef evaluate_responses(true_responses: list, predicted_responses: list) -> dict:\n \n    results = rouge_metric.compute(\n        predictions=predicted_responses,\n        references=true_responses,\n        use_stemmer=True\n    )\n    return results\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:31:40.103845Z","iopub.execute_input":"2025-02-07T05:31:40.104142Z","iopub.status.idle":"2025-02-07T05:31:41.522415Z","shell.execute_reply.started":"2025-02-07T05:31:40.104121Z","shell.execute_reply":"2025-02-07T05:31:41.521774Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34a343c5fd0f470cad1c69e217e8c974"}},"metadata":{}}],"execution_count":27},{"cell_type":"code","source":"from tqdm import tqdm\nfrom torch.utils.data import DataLoader\n\ndef batch_predict( batch_question):\n    input_texts = [\n        f\"Question: {Context}\"\n        for Context in zip(batch_question)\n    ]\n    inputs = tokenizer(input_texts, return_tensors=\"pt\", max_length=512, truncation=True, padding=True)\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n    with torch.no_grad():\n        outputs = model.generate(**inputs, max_length=75, num_return_sequences=1, do_sample=False)\n    return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n\nclass TestDataset(Dataset):\n    def __init__(self, df):\n        self.question = df['Context'].tolist()\n\n    def __len__(self):\n        return len(self.question)\n\n    def __getitem__(self, idx):\n        return  self.question[idx]\n\ntest_dataset = TestDataset(test_df)\ntest_loader = DataLoader(test_dataset, batch_size=40, shuffle=False)\n\npredicted_values = []\nprint(\"Starting prediction...\")\nfor batch in tqdm(test_loader, desc=\"Predicting\", unit=\"batch\"):\n    batch_question = batch\n    batch_predictions = batch_predict(batch_question)\n    predicted_values.extend(batch_predictions)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T21:16:48.575504Z","iopub.execute_input":"2025-02-06T21:16:48.575799Z","iopub.status.idle":"2025-02-06T21:16:55.120763Z","shell.execute_reply.started":"2025-02-06T21:16:48.575776Z","shell.execute_reply":"2025-02-06T21:16:55.120020Z"}},"outputs":[{"name":"stdout","text":"Starting prediction...\n","output_type":"stream"},{"name":"stderr","text":"Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:06<00:00,  1.31s/batch]\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"test_df.sample(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T21:17:01.156705Z","iopub.execute_input":"2025-02-06T21:17:01.157013Z","iopub.status.idle":"2025-02-06T21:17:01.165458Z","shell.execute_reply.started":"2025-02-06T21:17:01.156990Z","shell.execute_reply":"2025-02-06T21:17:01.164596Z"}},"outputs":[{"execution_count":33,"output_type":"execute_result","data":{"text/plain":"                                              Context  \\\n95  Thank you, Alex. Your words of encouragement m...   \n15  I hope they will understand, even if it takes ...   \n\n                                             Response  \n95  You're very welcome, Charlie. It's been a plea...  \n15  It's hopeful that you're willing to believe in...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Context</th>\n      <th>Response</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>95</th>\n      <td>Thank you, Alex. Your words of encouragement m...</td>\n      <td>You're very welcome, Charlie. It's been a plea...</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>I hope they will understand, even if it takes ...</td>\n      <td>It's hopeful that you're willing to believe in...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":33},{"cell_type":"code","source":"test_df['predicted_value'] = predicted_values\ntrue_responses = test_df['Response'].tolist()\npredicted_responses = test_df['predicted_value'].tolist()\n\n# Evaluate the predictions\nscores = evaluate_responses(true_responses, predicted_responses)\nprint(f\"Scores on Test Data: {scores}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-06T21:17:02.202680Z","iopub.execute_input":"2025-02-06T21:17:02.202966Z","iopub.status.idle":"2025-02-06T21:17:02.940909Z","shell.execute_reply.started":"2025-02-06T21:17:02.202945Z","shell.execute_reply":"2025-02-06T21:17:02.940169Z"}},"outputs":[{"name":"stdout","text":"Scores on Test Data: {'rouge1': 0.21725038521003956, 'rouge2': 0.053391473196168465, 'rougeL': 0.1598250419117268, 'rougeLsum': 0.16003325130502022}\n","output_type":"stream"}],"execution_count":34},{"cell_type":"code","source":"import torch\n\ntorch.cuda.empty_cache()\ntorch.cuda.reset_peak_memory_stats() \ntorch.cuda.reset_accumulated_memory_stats() ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:25:34.175663Z","iopub.execute_input":"2025-02-07T05:25:34.175996Z","iopub.status.idle":"2025-02-07T05:25:34.258478Z","shell.execute_reply.started":"2025-02-07T05:25:34.175969Z","shell.execute_reply":"2025-02-07T05:25:34.257766Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"import shutil\nmodel_dir = \"/kaggle/working/results/checkpoint-11088\"\nshutil.make_archive(\"fine_tuned_t5_checkpoints_1\", 'zip', model_dir)\n\nfrom IPython.display import FileLink\nFileLink(\"fine_tuned_t5_checkpoints_1.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:26:01.298444Z","iopub.execute_input":"2025-02-05T22:26:01.298678Z","iopub.status.idle":"2025-02-05T22:28:10.722509Z","shell.execute_reply.started":"2025-02-05T22:26:01.298656Z","shell.execute_reply":"2025-02-05T22:28:10.721687Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/fine_tuned_t5_checkpoints_1.zip","text/html":"<a href='fine_tuned_t5_checkpoints_1.zip' target='_blank'>fine_tuned_t5_checkpoints_1.zip</a><br>"},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"import shutil\nmodel_dir = \"/kaggle/working/fine_tuned_t5\"\n\nshutil.make_archive(\"fine_tuned_t5_epoch_1\", 'zip', model_dir)\n\nfrom IPython.display import FileLink\nFileLink(\"fine_tuned_t5_epoch_1.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-05T22:28:10.723691Z","iopub.execute_input":"2025-02-05T22:28:10.724041Z","iopub.status.idle":"2025-02-05T22:28:54.502624Z","shell.execute_reply.started":"2025-02-05T22:28:10.724006Z","shell.execute_reply":"2025-02-05T22:28:54.501790Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/fine_tuned_t5_epoch_1.zip","text/html":"<a href='fine_tuned_t5_epoch_1.zip' target='_blank'>fine_tuned_t5_epoch_1.zip</a><br>"},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"# Here, we load our checkpoints from epoch 1 to continue training for epoch 2.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_dir = \"/kaggle/input/arogo_epoch1_checkpoints/transformers/default/1\"\noutput_dir = \"/kaggle/working/\"\n\nif os.path.exists(model_dir):\n    model = AutoModelForSeq2SeqLM.from_pretrained(model_dir)\n    print(\"Resuming training from saved model.\")\nelse:\n    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n    print(\"Initializing new model.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:32:16.836611Z","iopub.execute_input":"2025-02-07T05:32:16.836920Z","iopub.status.idle":"2025-02-07T05:32:18.433211Z","shell.execute_reply.started":"2025-02-07T05:32:16.836899Z","shell.execute_reply":"2025-02-07T05:32:18.432177Z"}},"outputs":[{"name":"stdout","text":"Resuming training from saved model.\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"from safetensors.torch import load_file\nfrom transformers import AutoModelForSeq2SeqLM","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:32:18.434622Z","iopub.execute_input":"2025-02-07T05:32:18.434924Z","iopub.status.idle":"2025-02-07T05:32:18.440290Z","shell.execute_reply.started":"2025-02-07T05:32:18.434894Z","shell.execute_reply":"2025-02-07T05:32:18.438838Z"}},"outputs":[],"execution_count":29},{"cell_type":"code","source":"\n\nwritable_model_dir = \"/kaggle/working/arogo_epoch1_checkpoint\"\n\nos.makedirs(writable_model_dir, exist_ok=True)\n\nsafetensor_path = os.path.join(model_dir, \"model.safetensors\")\nmodel_state_dict = load_file(safetensor_path)\n\ntorch.save(model_state_dict, os.path.join(writable_model_dir, \"pytorch_model.bin\"))\n\nimport shutil\n\nrequired_files = [\"config.json\", \"trainer_state.json\", \"training_args.bin\", \"scheduler.pt\", \"optimizer.pt\", \"rng_state.pth\", \"generation_config.json\"]\n\nfor file_name in required_files:\n    src = os.path.join(model_dir, file_name)\n    dst = os.path.join(writable_model_dir, file_name)\n    if os.path.exists(src):\n        shutil.copy(src, dst)\n\nmodel = AutoModelForSeq2SeqLM.from_pretrained(writable_model_dir)\nprint(\"Resuming training from saved model.\")\n\noutput_dir = \"/kaggle/working/\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:32:24.431821Z","iopub.execute_input":"2025-02-07T05:32:24.432108Z","iopub.status.idle":"2025-02-07T05:32:56.597222Z","shell.execute_reply.started":"2025-02-07T05:32:24.432088Z","shell.execute_reply":"2025-02-07T05:32:56.596132Z"}},"outputs":[{"name":"stdout","text":"Resuming training from saved model.\n","output_type":"stream"}],"execution_count":30},{"cell_type":"code","source":"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel.to(device)\n\nfrom transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n\ntraining_args = Seq2SeqTrainingArguments(\n    output_dir=output_dir,\n    num_train_epochs=2,  # Additional epoch but it resume training for 2nd epoch\n    per_device_train_batch_size=24,\n    per_device_eval_batch_size=24,\n    warmup_steps=500,\n    weight_decay=0.01,\n    logging_dir=\"./logs\",\n    logging_steps=10,\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"epoch\",\n    save_total_limit=2,\n    load_best_model_at_end=True,\n    learning_rate=1e-3,\n)\n\ntrainer = Seq2SeqTrainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=eval_dataset,\n)\n\nmodel_dir = '/kaggle/working/arogo_epoch1_checkpoint'\ntrainer.train(resume_from_checkpoint=model_dir)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T05:32:56.598460Z","iopub.execute_input":"2025-02-07T05:32:56.598774Z","iopub.status.idle":"2025-02-07T09:03:27.735213Z","shell.execute_reply.started":"2025-02-07T05:32:56.598743Z","shell.execute_reply":"2025-02-07T09:03:27.734517Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1575: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n  warnings.warn(\nUsing the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\nThere were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3418: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  torch.load(os.path.join(checkpoint, OPTIMIZER_NAME), map_location=map_location)\n/usr/local/lib/python3.10/dist-packages/transformers/trainer.py:3081: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  checkpoint_rng_state = torch.load(rng_file)\nPassing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='22176' max='22176' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [22176/22176 3:30:23, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>2</td>\n      <td>0.814200</td>\n      <td>0.788302</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight', 'lm_head.weight'].\n","output_type":"stream"},{"execution_count":31,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=22176, training_loss=0.4283540972211488, metrics={'train_runtime': 12625.1927, 'train_samples_per_second': 42.153, 'train_steps_per_second': 1.756, 'total_flos': 1.89889245720576e+17, 'train_loss': 0.4283540972211488, 'epoch': 2.0})"},"metadata":{}}],"execution_count":31},{"cell_type":"code","source":"model.save_pretrained(\"./fine_tuned_t5_v2\")\ntokenizer.save_pretrained(\"./fine_tuned_t5_v2\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T09:03:31.867088Z","iopub.execute_input":"2025-02-07T09:03:31.867380Z","iopub.status.idle":"2025-02-07T09:03:33.942217Z","shell.execute_reply.started":"2025-02-07T09:03:31.867359Z","shell.execute_reply":"2025-02-07T09:03:33.941261Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"('./fine_tuned_t5_v2/tokenizer_config.json',\n './fine_tuned_t5_v2/special_tokens_map.json',\n './fine_tuned_t5_v2/spiece.model',\n './fine_tuned_t5_v2/added_tokens.json',\n './fine_tuned_t5_v2/tokenizer.json')"},"metadata":{}}],"execution_count":32},{"cell_type":"code","source":"model = AutoModelForSeq2SeqLM.from_pretrained(\"./fine_tuned_t5_v2\")\nmodel.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T09:30:11.905567Z","iopub.execute_input":"2025-02-07T09:30:11.905880Z","iopub.status.idle":"2025-02-07T09:30:12.627459Z","shell.execute_reply.started":"2025-02-07T09:30:11.905859Z","shell.execute_reply":"2025-02-07T09:30:12.626717Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"execution_count":39,"output_type":"execute_result","data":{"text/plain":"T5ForConditionalGeneration(\n  (shared): Embedding(32128, 768)\n  (encoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (decoder): T5Stack(\n    (embed_tokens): Embedding(32128, 768)\n    (block): ModuleList(\n      (0): T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n              (relative_attention_bias): Embedding(32, 12)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n      (1-11): 11 x T5Block(\n        (layer): ModuleList(\n          (0): T5LayerSelfAttention(\n            (SelfAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (1): T5LayerCrossAttention(\n            (EncDecAttention): T5Attention(\n              (q): Linear(in_features=768, out_features=768, bias=False)\n              (k): Linear(in_features=768, out_features=768, bias=False)\n              (v): Linear(in_features=768, out_features=768, bias=False)\n              (o): Linear(in_features=768, out_features=768, bias=False)\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (2): T5LayerFF(\n            (DenseReluDense): T5DenseActDense(\n              (wi): Linear(in_features=768, out_features=3072, bias=False)\n              (wo): Linear(in_features=3072, out_features=768, bias=False)\n              (dropout): Dropout(p=0.1, inplace=False)\n              (act): ReLU()\n            )\n            (layer_norm): T5LayerNorm()\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (final_layer_norm): T5LayerNorm()\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n)"},"metadata":{}}],"execution_count":39},{"cell_type":"code","source":"from tqdm import tqdm\nfrom torch.utils.data import DataLoader\n\ndef batch_predict( batch_question):\n    input_texts = [\n        f\"Question: {Context}\"\n        for Context in zip(batch_question)\n    ]\n    inputs = tokenizer(input_texts, return_tensors=\"pt\", max_length=512, truncation=True, padding=True)\n    inputs = {k: v.to(device) for k, v in inputs.items()}\n    with torch.no_grad():\n        outputs = model.generate(**inputs, max_length=75, num_return_sequences=1, do_sample=False)\n    return [tokenizer.decode(output, skip_special_tokens=True) for output in outputs]\n\nclass TestDataset(Dataset):\n    def __init__(self, df):\n        self.question = df['Context'].tolist()\n\n    def __len__(self):\n        return len(self.question)\n\n    def __getitem__(self, idx):\n        return  self.question[idx]\n\ntest_dataset = TestDataset(test_df)\ntest_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n\npredicted_values = []\nprint(\"Starting prediction...\")\nfor batch in tqdm(test_loader, desc=\"Predicting\", unit=\"batch\"):\n    batch_question = batch\n    batch_predictions = batch_predict(batch_question)\n    predicted_values.extend(batch_predictions)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T09:30:32.046659Z","iopub.execute_input":"2025-02-07T09:30:32.046947Z","iopub.status.idle":"2025-02-07T09:50:37.693753Z","shell.execute_reply.started":"2025-02-07T09:30:32.046927Z","shell.execute_reply":"2025-02-07T09:50:37.692849Z"}},"outputs":[{"name":"stdout","text":"Starting prediction...\n","output_type":"stream"},{"name":"stderr","text":"Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 938/938 [20:05<00:00,  1.29s/batch]\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"test_df['predicted_value'] = predicted_values\ntrue_responses = test_df['Response'].tolist()\npredicted_responses = test_df['predicted_value'].tolist()\n\nscores = evaluate_responses(true_responses, predicted_responses)\nprint(f\"Scores on Test Data: {scores}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T09:50:37.694664Z","iopub.execute_input":"2025-02-07T09:50:37.694954Z","iopub.status.idle":"2025-02-07T09:52:39.221187Z","shell.execute_reply.started":"2025-02-07T09:50:37.694912Z","shell.execute_reply":"2025-02-07T09:52:39.220406Z"}},"outputs":[{"name":"stdout","text":"Scores on Test Data: {'rouge1': 0.402221357225255, 'rouge2': 0.15462024487508397, 'rougeL': 0.2864835837035713, 'rougeLsum': 0.28646795927183055}\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"# 1st epoch values\n#Scores on Test Data: {'rouge1': 0.41203100050344876, 'rouge2': 0.16337853205553043, 'rougeL': 0.29616798143440815, 'rougeLsum': 0.29625279155455775}","metadata":{"trusted":true,"execution":{"execution_failed":"2025-02-05T17:33:38.129Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import shutil\nmodel_dir = \"/kaggle/working/fine_tuned_t5_v2\"\n\nshutil.make_archive(\"fine_tuned_t5_epoch_2\", 'zip', model_dir)\n\nfrom IPython.display import FileLink\nFileLink(\"fine_tuned_t5_epoch_2.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T09:26:21.022705Z","iopub.execute_input":"2025-02-07T09:26:21.022917Z","iopub.status.idle":"2025-02-07T09:27:04.855174Z","shell.execute_reply.started":"2025-02-07T09:26:21.022899Z","shell.execute_reply":"2025-02-07T09:27:04.854320Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/fine_tuned_t5_epoch_2.zip","text/html":"<a href='fine_tuned_t5_epoch_2.zip' target='_blank'>fine_tuned_t5_epoch_2.zip</a><br>"},"metadata":{}}],"execution_count":35},{"cell_type":"code","source":"import shutil\nmodel_dir = \"/kaggle/working/checkpoint-22176\"\n\nshutil.make_archive(\"fine_tuned_t5_checkpoints_2\", 'zip', model_dir)\n\nfrom IPython.display import FileLink\nFileLink(\"fine_tuned_t5_checkpoints_2.zip\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T09:27:04.856269Z","iopub.execute_input":"2025-02-07T09:27:04.856586Z","iopub.status.idle":"2025-02-07T09:29:16.129015Z","shell.execute_reply.started":"2025-02-07T09:27:04.856556Z","shell.execute_reply":"2025-02-07T09:29:16.128230Z"}},"outputs":[{"execution_count":36,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/fine_tuned_t5_checkpoints_2.zip","text/html":"<a href='fine_tuned_t5_checkpoints_2.zip' target='_blank'>fine_tuned_t5_checkpoints_2.zip</a><br>"},"metadata":{}}],"execution_count":36},{"cell_type":"code","source":"test_df['predicted_value'].iloc[80]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T09:29:16.129913Z","iopub.execute_input":"2025-02-07T09:29:16.130234Z","iopub.status.idle":"2025-02-07T09:29:16.135343Z","shell.execute_reply.started":"2025-02-07T09:29:16.130201Z","shell.execute_reply":"2025-02-07T09:29:16.134718Z"}},"outputs":[{"execution_count":37,"output_type":"execute_result","data":{"text/plain":"\"(Curiously) Your commitment to finding a balance and fostering a cooperative environment is truly inspiring, Charlie. Remember, change takes time, and it's essential to be patient with yourself and your family members throughout this process. Is there anything else you'd like to discuss or any other concerns you have?\""},"metadata":{}}],"execution_count":37},{"cell_type":"code","source":"test_df['Response'].iloc[80]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-07T09:29:16.136093Z","iopub.execute_input":"2025-02-07T09:29:16.136333Z","iopub.status.idle":"2025-02-07T09:29:16.151762Z","shell.execute_reply.started":"2025-02-07T09:29:16.136313Z","shell.execute_reply":"2025-02-07T09:29:16.151073Z"}},"outputs":[{"execution_count":38,"output_type":"execute_result","data":{"text/plain":"\"It's fantastic to see your determination and willingness to take the lead in initiating a positive change within your family. Remember, change takes time and effort, so be patient with yourself and your family members as you navigate this process. Is there anything else you'd like to discuss or any additional goals you would like to set for yourself?\""},"metadata":{}}],"execution_count":38},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}